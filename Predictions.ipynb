{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMP6ZgOOIFTKQQinkyhytKV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pascalghanimi/Ski-Classification-AI/blob/main/Predictions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "import pickle\n",
        "\n",
        "# ─── Attention Klasse definieren ───────────────────────────────────────────────\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super().__init__()\n",
        "        self.attn = nn.Linear(hidden_size * 4, hidden_size)  # Korrigierte Dimension\n",
        "        self.v = nn.Linear(hidden_size, 1, bias=False)\n",
        "\n",
        "    def forward(self, hidden, outputs):\n",
        "        hidden = hidden.unsqueeze(1).repeat(1, outputs.size(1), 1)\n",
        "        combined = torch.cat((hidden, outputs), dim=2)\n",
        "        energy = torch.tanh(self.attn(combined))\n",
        "        attention = torch.softmax(self.v(energy).squeeze(2), dim=1)\n",
        "        return torch.sum(attention.unsqueeze(2) * outputs, dim=1)\n",
        "\n",
        "# ─── Modellklasse definieren ───────────────────────────────────────────────────\n",
        "class SkiSwingLSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size,\n",
        "            hidden_size,\n",
        "            num_layers=2,\n",
        "            bidirectional=True,\n",
        "            batch_first=True,\n",
        "            dropout=0.4\n",
        "        )\n",
        "        self.attention = Attention(hidden_size)\n",
        "        self.dropout = nn.Dropout(0.6)\n",
        "        self.fc = nn.Linear(hidden_size * 2, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        outputs, (hidden, _) = self.lstm(x)\n",
        "        hidden_combined = torch.cat((hidden[-2], hidden[-1]), dim=1)\n",
        "        context = self.attention(hidden_combined, outputs)\n",
        "        return self.fc(self.dropout(context))\n",
        "\n",
        "# ─── Konfiguration ────────────────────────────────────────────────────────────\n",
        "MAX_LENGTH = 400\n",
        "FEATURE_FILE = \"PHALP_AMichi_2_features.pkl\"\n",
        "SCALER_FILE  = \"scaler_schwung.pkl\"\n",
        "ENCODER_FILE = \"encoder_schwung.pkl\"\n",
        "INPUT_VIDEO = \"PHALP_AMichi_2.mp4\"\n",
        "OUTPUT_VIDEO = \"annotated_output.mp4\"\n",
        "MODEL = \"ski_schwung_classifier.pt\"\n",
        "\n",
        "# ─── Scaler & Encoder laden ───────────────────────────────────────────────────\n",
        "with open(SCALER_FILE, \"rb\") as f:\n",
        "    scaler = pickle.load(f)\n",
        "\n",
        "with open(ENCODER_FILE, \"rb\") as f:\n",
        "    le = pickle.load(f)\n",
        "\n",
        "# ─── Features laden ───────────────────────────────────────────────────────────\n",
        "with open(FEATURE_FILE, \"rb\") as f:\n",
        "    features = pickle.load(f)\n",
        "\n",
        "# ─── Daten vorbereiten ────────────────────────────────────────────────────────\n",
        "data = []\n",
        "frames = sorted(f for f in features[\"COM_to_ground\"] if isinstance(f, int))\n",
        "\n",
        "for frame in frames:\n",
        "    frame_features = [\n",
        "        features[\"COM_to_ground\"][frame],\n",
        "        features[\"knee_angles_right\"][frame],\n",
        "        features[\"knee_angles_left\"][frame]\n",
        "    ]\n",
        "\n",
        "    # Füge joint_angles hinzu\n",
        "    for axis in features[\"joint_angles\"][frame]:\n",
        "        frame_features.extend(\n",
        "            features[\"joint_angles\"][frame][axis].values()\n",
        "        )\n",
        "\n",
        "    # Füge axis_angles hinzu\n",
        "    for axis in features[\"axis_angles\"][frame]:\n",
        "        frame_features.extend(\n",
        "            features[\"axis_angles\"][frame][axis].values()\n",
        "        )\n",
        "\n",
        "    # Füge COM_angles hinzu\n",
        "    frame_features.extend(features[\"COM_angles\"][frame].values())\n",
        "\n",
        "    data.append(frame_features)\n",
        "\n",
        "# Konvertiere zu numpy array\n",
        "data = np.array(data, dtype=np.float32)\n",
        "\n",
        "# Padden oder trimmen auf MAX_LENGTH\n",
        "if data.shape[0] < MAX_LENGTH:\n",
        "    pad = np.zeros((MAX_LENGTH - data.shape[0], data.shape[1]), dtype=np.float32)\n",
        "    data = np.vstack([data, pad])\n",
        "else:\n",
        "    data = data[:MAX_LENGTH]\n",
        "\n",
        "# Skalieren\n",
        "data_scaled = scaler.transform(data)\n",
        "\n",
        "# Zu Tensor konvertieren\n",
        "x = torch.tensor(data_scaled, dtype=torch.float32).unsqueeze(0)  # [1, seq_len, feat_dim]\n",
        "\n",
        "# ─── Modell laden ─────────────────────────────────────────────────────────────\n",
        "# Füge sichere Klassen hinzu für das Laden\n",
        "torch.serialization.add_safe_globals([\n",
        "    SkiSwingLSTM,\n",
        "    Attention,\n",
        "    nn.LSTM,\n",
        "    nn.Linear,\n",
        "    nn.Dropout\n",
        "])\n",
        "\n",
        "# Modell laden\n",
        "model = torch.load(MODEL, map_location=\"cpu\")\n",
        "model.eval()\n",
        "\n",
        "# ─── Vorhersage machen ────────────────────────────────────────────────────────\n",
        "with torch.no_grad():\n",
        "    logits = model(x)\n",
        "    style_idx = logits.argmax(dim=1).item()\n",
        "\n",
        "# Klassennamen dekodieren\n",
        "style_str = le.inverse_transform([style_idx])[0]\n",
        "print(\"Vorhergesagte Schwungart:\", style_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDI4VVIzL4II",
        "outputId": "77c03cc7-a658-4c82-a96e-52edd1e5b5fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vorhergesagte Schwungart: PDK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import cv2\n",
        "\n",
        "# ─── 2. Turn-Klassifikationsmodell ────────────────────────────────────────────\n",
        "class FrameWiseLSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size,\n",
        "                            num_layers=2, bidirectional=True,\n",
        "                            batch_first=True, dropout=0.3)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.fc = nn.Linear(hidden_size * 2, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        return self.fc(self.dropout(out))\n",
        "\n",
        "# Füge sichere Klassen für Deserialisierung hinzu\n",
        "torch.serialization.add_safe_globals([FrameWiseLSTM, nn.LSTM])\n",
        "\n",
        "# ─── 3. Features laden und verarbeiten ────────────────────────────────────────\n",
        "with open(FEATURE_FILE, \"rb\") as f:\n",
        "    features = pickle.load(f)\n",
        "\n",
        "# Extrahiere Frame-Indizes\n",
        "frame_indices = sorted([f for f in features[\"COM_to_ground\"].keys() if isinstance(f, int)])\n",
        "\n",
        "# Baue die Sequenz für die Turn-Klassifikation auf\n",
        "seq_turn = []\n",
        "for i in frame_indices:\n",
        "    try:\n",
        "        v = [\n",
        "            features[\"COM_to_ground\"][i],\n",
        "            features[\"knee_angles_right\"][i],\n",
        "            features[\"knee_angles_left\"][i]\n",
        "        ]\n",
        "\n",
        "        # Füge joint_angles hinzu\n",
        "        for axis in features[\"joint_angles\"][i]:\n",
        "            v.extend(features[\"joint_angles\"][i][axis].values())\n",
        "\n",
        "        # Füge axis_angles hinzu\n",
        "        for axis in features[\"axis_angles\"][i]:\n",
        "            v.extend(features[\"axis_angles\"][i][axis].values())\n",
        "\n",
        "        # Füge COM_angles hinzu\n",
        "        v.extend(features[\"COM_angles\"][i].values())\n",
        "\n",
        "        # Füge style_idx als zusätzliches Feature hinzu\n",
        "        v.append(style_idx)\n",
        "\n",
        "        seq_turn.append(v)\n",
        "    except KeyError as e:\n",
        "        print(f\"Fehlendes Feature in Frame {i}: {e}\")\n",
        "        continue\n",
        "\n",
        "if not seq_turn:\n",
        "    raise RuntimeError(\"Turn-Sequence ist leer – bitte Features prüfen!\")\n",
        "\n",
        "# Konvertiere zu Tensor\n",
        "arr_turn = np.array(seq_turn, dtype=np.float32)\n",
        "x_turn = torch.tensor(arr_turn).unsqueeze(0).float()  # [1, n_frames, feat_dim+1]\n",
        "\n",
        "# ─── 4. Modell laden und Vorhersage treffen ───────────────────────────────────\n",
        "# Modell laden\n",
        "model_turn = torch.load(\"left_right_classifier.pt\", map_location=\"cpu\")\n",
        "model_turn.eval()\n",
        "\n",
        "# Vorhersage treffen\n",
        "with torch.no_grad():\n",
        "    logits = model_turn(x_turn)\n",
        "    preds = logits.argmax(dim=-1).squeeze().numpy()\n",
        "\n",
        "# Labels erstellen\n",
        "labels_turn = [\"Linksschwung\" if p == 1 else \"Rechtsschwung\" for p in preds]\n",
        "print(\"Schwung pro Frame:\", labels_turn)\n",
        "\n",
        "# ─── 5. Video annotieren ──────────────────────────────────────────────────────\n",
        "# Video öffnen\n",
        "cap = cv2.VideoCapture(INPUT_VIDEO)\n",
        "if not cap.isOpened():\n",
        "    raise RuntimeError(f\"Konnte Video {INPUT_VIDEO} nicht öffnen\")\n",
        "\n",
        "# Video-Writer einrichten\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(OUTPUT_VIDEO, fourcc, fps, (w, h))\n",
        "\n",
        "# Frame-Zähler\n",
        "frame_count = 0\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Nur annotieren, wenn wir ein Label für diesen Frame haben\n",
        "    if frame_count < len(labels_turn):\n",
        "        swing_txt = labels_turn[frame_count]\n",
        "\n",
        "        # Annotationen hinzufügen\n",
        "        cv2.putText(frame, swing_txt, (50, 80),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 0, 255), 3)\n",
        "        cv2.putText(frame, f\"Fahrstil: {style_str}\", (50, h-30),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 255), 2)\n",
        "\n",
        "    # Frame schreiben\n",
        "    out.write(frame)\n",
        "    frame_count += 1\n",
        "\n",
        "# Ressourcen freigeben\n",
        "cap.release()\n",
        "out.release()\n",
        "print(f\"Annotiertes Video wurde gespeichert als '{OUTPUT_VIDEO}'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8CIORXkU_gQ",
        "outputId": "082a8c01-803e-4484-bb7d-83927ec63e68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Schwung pro Frame: ['Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Rechtsschwung', 'Linksschwung', 'Linksschwung', 'Linksschwung']\n",
            "Annotiertes Video wurde gespeichert als 'annotated_output.mp4'\n"
          ]
        }
      ]
    }
  ]
}