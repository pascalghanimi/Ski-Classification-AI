{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNuA987cGkyFmbz1cRuSCRt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pascalghanimi/Ski-Classification-AI/blob/main/Deep_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "\n",
        "pickle_file = \"features_with_labels.pkl\"\n",
        "\n",
        "with open(pickle_file, \"rb\") as pkl_file:\n",
        "  features_with_labels_dic = pickle.load(pkl_file)\n",
        "\n",
        "print(features_with_labels_dic[\"joint_angles\"][0][\"x\"][\"x_shoulder_to_ellbow_right_axis_angle\"])\n",
        "\n",
        "selected_features = [\"COM_to_ground\", \"knee_angles_right\", \"knee_angles_left\"]\n",
        "selected_nested_features = [\"joint_angles\", \"axis_angles\"]\n",
        "frames = list(features_with_labels_dic[\"COM_to_ground\"].keys())\n",
        "labels = [features_with_labels_dic[\"schwung_labels\"][frame] for frame in frames]\n",
        "\n",
        "print(frames)\n",
        "\n",
        "data = {\"Frame\": frames, \"Label\": labels}\n",
        "\n",
        "for feature in selected_features:\n",
        "  data[feature] = [features_with_labels_dic[feature][frame] for frame in frames]\n",
        "\n",
        "for feature in selected_nested_features:\n",
        "  for frame in frames:\n",
        "    for coordinate in features_with_labels_dic[feature][frame]:\n",
        "      for feature_name in features_with_labels_dic[feature][frame][coordinate]:\n",
        "        if feature_name not in data:\n",
        "          data[feature_name] = []  # Falls nicht vorhanden, erstelle eine Liste\n",
        "        data[feature_name].append(features_with_labels_dic[feature][frame][coordinate][feature_name])\n",
        "\n",
        "print(list(data.keys()))\n",
        "\n",
        "pd.set_option(\"display.max_columns\", None)\n",
        "df = pd.DataFrame(data)\n",
        "df.head()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "816i3UPzd27T",
        "outputId": "5b48e904-7e37-4b59-b715-6f24fd5d33b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'features_with_labels.pkl'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-64a976df3e55>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpickle_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"features_with_labels.pkl\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpkl_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mfeatures_with_labels_dic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkl_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'features_with_labels.pkl'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "selected_features = [col for col in df.columns if col not in [\"Frame\", \"Label\"]]\n",
        "\n",
        "X = df[selected_features].values.reshape(1, -1, len(selected_features))\n",
        "Y = df[\"Label\"].values.reshape(1, -1)\n",
        "\n",
        "X_train = torch.tensor(X, dtype=torch.float32)\n",
        "Y_train = torch.tensor(Y, dtype=torch.long)\n",
        "\n",
        "class MyLSTMModel(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "     super(MyLSTMModel, self).__init__()\n",
        "     self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first = True)\n",
        "     self.fc = nn.Linear(hidden_size, output_size)"
      ],
      "metadata": {
        "id": "w2fPUF3-bR8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mn8OgqHyxC0k",
        "outputId": "bf48ded9-c92b-4142-db8b-fddf9a00c6b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 1.2369199991226196\n",
            "Epoch 10, Loss: 0.9103463292121887\n",
            "Epoch 20, Loss: 0.6348735690116882\n",
            "Epoch 30, Loss: 0.3476511836051941\n",
            "Epoch 40, Loss: 0.14514248073101044\n",
            "Training abgeschlossen! ðŸš€\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "# ðŸ”¹ **Alle Features auÃŸer Frame & Label als Input**\n",
        "selected_features = [col for col in df.columns if col not in [\"Frame\", \"Label\"]]\n",
        "\n",
        "# **LSTM Input vorbereiten** -> reshape ist aufgebaut wie folgt (Anzahl Videos, Anzahl Frames (-1 berechnet Python Anzahl automatisch), Anzahl Features)\n",
        "X = df[selected_features].values.reshape(1, -1, len(selected_features))  # (Batch=1, Time, Features)\n",
        "Y = df[\"Label\"].values.reshape(1, -1)  # (Batch=1, Time)\n",
        "\n",
        "# **In Torch-Tensor umwandeln**\n",
        "X_train = torch.tensor(X, dtype=torch.float32)\n",
        "Y_train = torch.tensor(Y, dtype=torch.long)\n",
        "\n",
        "# ðŸ”¹ **LSTM-Modell definieren**\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "        out = self.fc(lstm_out)\n",
        "        return out\n",
        "\n",
        "# ðŸ”¹ **Modell initialisieren**\n",
        "input_size = len(selected_features)  # **Alle Features als Input**\n",
        "hidden_size = 64\n",
        "num_layers = 2\n",
        "output_size = 3  # **0 = Kein Schwung, 1 = Linksschwung, 2 = Rechtsschwung**\n",
        "\n",
        "model = LSTMModel(input_size, hidden_size, num_layers, output_size)\n",
        "\n",
        "# ðŸ”¹ **Loss & Optimizer**\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# ðŸ”¹ **Training**\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(X_train)\n",
        "    loss = criterion(outputs.squeeze(0), Y_train.squeeze(0))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
        "\n",
        "print(\"Training abgeschlossen! ðŸš€\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():  # Keine Gradientenberechnung nÃ¶tig\n",
        "    predictions = model(X_train)\n",
        "    predicted_classes = torch.argmax(predictions, dim=2)  # Klasse mit hÃ¶chster Wahrscheinlichkeit\n",
        "print(predicted_classes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCfIcc2piBVs",
        "outputId": "288d35d9-9bbe-4c2f-e7e7-1a3c38edb754"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2,\n",
            "         2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "         2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = (predicted_classes.squeeze(0) == Y_train.squeeze(0)).sum().item()\n",
        "accuracy = correct / len(Y_train.squeeze(0))\n",
        "print(f\"Modellgenauigkeit: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsm4sTBiiDGY",
        "outputId": "cc30a889-e195-4d46-8165-2efe8b1f6943"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modellgenauigkeit: 0.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "# ðŸ”¹ **Alle Features auÃŸer Frame & Label als Input**\n",
        "selected_features = [col for col in df.columns if col not in [\"Frame\", \"Label\"]]\n",
        "\n",
        "# **GRU Input vorbereiten**\n",
        "X = df[selected_features].values.reshape(1, -1, len(selected_features))  # (Batch=1, Time, Features)\n",
        "Y = df[\"Label\"].values.reshape(1, -1)  # (Batch=1, Time)\n",
        "\n",
        "# **In Torch-Tensor umwandeln**\n",
        "X_train = torch.tensor(X, dtype=torch.float32)\n",
        "Y_train = torch.tensor(Y, dtype=torch.long)\n",
        "\n",
        "# ðŸ”¹ **GRU-Modell definieren**\n",
        "class GRUModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super(GRUModel, self).__init__()\n",
        "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        gru_out, _ = self.gru(x)\n",
        "        out = self.fc(gru_out)\n",
        "        return out\n",
        "\n",
        "# ðŸ”¹ **Modell initialisieren**\n",
        "input_size = len(selected_features)  # **Alle Features als Input**\n",
        "hidden_size = 64\n",
        "num_layers = 2\n",
        "output_size = 3  # **0 = Kein Schwung, 1 = Linksschwung, 2 = Rechtsschwung**\n",
        "\n",
        "model = GRUModel(input_size, hidden_size, num_layers, output_size)\n",
        "\n",
        "# ðŸ”¹ **Loss & Optimizer**\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# ðŸ”¹ **Training**\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(X_train)\n",
        "    loss = criterion(outputs.squeeze(0), Y_train.squeeze(0))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
        "\n",
        "print(\"Training abgeschlossen! ðŸš€\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65LUGB65ylVh",
        "outputId": "09e61141-b80a-4d28-f53a-f4e83cc54b91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 1.0510342121124268\n",
            "Epoch 10, Loss: 0.5786163210868835\n",
            "Epoch 20, Loss: 0.42098215222358704\n",
            "Epoch 30, Loss: 0.22384342551231384\n",
            "Epoch 40, Loss: 0.08048948645591736\n",
            "Training abgeschlossen! ðŸš€\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():  # Keine Gradientenberechnung nÃ¶tig\n",
        "    predictions_gru = model(X_train)  # Nutze \"model\" statt \"gru_model\"\n",
        "    predicted_classes_gru = torch.argmax(predictions_gru, dim=2)  # Klasse mit hÃ¶chster Wahrscheinlichkeit\n",
        "print(predicted_classes_gru)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5czvTvKzFCX",
        "outputId": "1d8af802-8c15-48bc-c3c8-87679d0e81ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2,\n",
            "         2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "         2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    predictions_gru = model(X_train)\n",
        "    predicted_classes_gru = torch.argmax(predictions_gru, dim=2)\n",
        "\n",
        "correct_gru = (predicted_classes_gru.squeeze(0) == Y_train.squeeze(0)).sum().item()\n",
        "accuracy_gru = correct_gru / len(Y_train.squeeze(0))\n",
        "print(f\"GRU-Modellgenauigkeit: {accuracy_gru:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZ01qGvazWIS",
        "outputId": "4a091363-2a44-4c50-c6ef-b17ad2ff6c90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GRU-Modellgenauigkeit: 0.99\n"
          ]
        }
      ]
    }
  ]
}